import axios from 'axios';
import FormData from 'form-data';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import ffmpeg from 'fluent-ffmpeg';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * In-memory storage for room recordings
 */
const roomRecordings = new Map();

/**
 * Start recording for a room
 */
export const startRecording = (roomId) => {
    console.log(`ğŸ™ï¸ Starting recording for room: ${roomId}`);

    roomRecordings.set(roomId, {
        roomId,
        startTime: new Date(),
        audioChunks: [],
        isRecording: true
    });

    return { success: true, message: 'Recording started' };
};

/**
 * Add audio chunk to recording
 */
export const addAudioChunk = (roomId, audioData) => {
    const recording = roomRecordings.get(roomId);
    if (recording && recording.isRecording) {
        recording.audioChunks.push(audioData);
        return { success: true };
    }
    return { success: false, message: 'No active recording found' };
};

/**
 * Stop recording and process the audio
 */
export const stopRecording = async (roomId) => {
    console.log(`â¹ï¸ Stopping recording for room: ${roomId}`);

    const recording = roomRecordings.get(roomId);
    if (!recording) {
        return { success: false, message: 'No recording found' };
    }

    recording.isRecording = false;
    recording.endTime = new Date();

    return { success: true, recording };
};

/**
 * Save audio blob to file
 */
export const saveAudioFile = async (audioBlob, roomId) => {
    const recordingsDir = path.join(__dirname, '../../recordings');

    if (!fs.existsSync(recordingsDir)) {
        fs.mkdirSync(recordingsDir, { recursive: true });
    }

    const filename = `room_${roomId}_${Date.now()}.webm`;
    const filepath = path.join(recordingsDir, filename);

    fs.writeFileSync(filepath, Buffer.from(audioBlob));

    console.log(`ğŸ’¾ Audio saved to: ${filepath}`);
    return filepath;
};

/**
 * Wait for file to be fully written and validate it
 */
const waitForFile = async (filePath, maxWaitMs = 3000) => {
    const startTime = Date.now();
    let lastSize = 0;

    while (Date.now() - startTime < maxWaitMs) {
        if (fs.existsSync(filePath)) {
            const stats = fs.statSync(filePath);
            const currentSize = stats.size;

            // File exists and has content
            if (currentSize > 0) {
                // Wait a bit and check if size is stable
                await new Promise(resolve => setTimeout(resolve, 500));
                const newStats = fs.statSync(filePath);

                if (newStats.size === currentSize && currentSize > 1000) {
                    // File size is stable and reasonable
                    console.log(`âœ… File ready: ${path.basename(filePath)} (${currentSize} bytes)`);
                    return true;
                }
            }
            lastSize = currentSize;
        }
        await new Promise(resolve => setTimeout(resolve, 200));
    }

    console.warn(`âš ï¸ File wait timeout: ${path.basename(filePath)}`);
    return false;
};

/**
 * Convert WebM to WAV for Gemini API compatibility
 */
const convertToWav = async (inputPath) => {
    // Wait for file to be fully written
    const isReady = await waitForFile(inputPath);
    if (!isReady) {
        throw new Error('File not ready for conversion');
    }

    return new Promise((resolve, reject) => {
        const outputPath = inputPath.replace('.webm', '.wav');

        console.log(`ğŸ”„ Converting ${path.basename(inputPath)} to WAV...`);

        ffmpeg(inputPath)
            .toFormat('wav')
            .audioCodec('pcm_s16le')
            .audioChannels(1)
            .audioFrequency(16000)
            .on('end', () => {
                console.log(`âœ… Conversion complete: ${path.basename(outputPath)}`);
                resolve(outputPath);
            })
            .on('error', (err) => {
                console.error('âŒ FFmpeg conversion error:', err.message);
                reject(err);
            })
            .save(outputPath);
    });
};

/**
 * Map Gemini API response to our display format
 */
const mapGeminiResponseToTranscript = (geminiData) => {
    const chiSoSinhTon = geminiData.CHI_SO_SINH_TON_NB_CHI_SO_SONG || {};
    const hoiBenh = geminiData.HOI_BENH_NB_HOI_BENH || {};
    const khamLamSang = geminiData.KHAM_LAM_SANG_NB_KHAM_XET || {};
    const chanDoan = geminiData.CHAN_DOAN_NB_CHAN_DOAN || {};
    const ketLuan = geminiData.KET_LUAN_NB_KET_LUAN || {};
    const canLamSang = geminiData.CAN_LAM_SANG_TOM_TAT_NB_TOM_TAT_CLS || {};

    // Build clinical summary
    const lamSangParts = [];
    if (khamLamSang.toanThan) lamSangParts.push(`ToÃ n thÃ¢n: ${khamLamSang.toanThan}`);
    if (khamLamSang.tim) lamSangParts.push(`Tim: ${khamLamSang.tim}`);
    if (khamLamSang.phoi) lamSangParts.push(`Phá»•i: ${khamLamSang.phoi}`);
    if (khamLamSang.bung) lamSangParts.push(`Bá»¥ng: ${khamLamSang.bung}`);

    // Build vital signs summary
    const vitalSignsParts = [];
    if (chiSoSinhTon.mach) vitalSignsParts.push(`Máº¡ch: ${chiSoSinhTon.mach} nhá»‹p/phÃºt`);
    if (chiSoSinhTon.nhietDo) vitalSignsParts.push(`Nhiá»‡t Ä‘á»™: ${chiSoSinhTon.nhietDo}Â°C`);
    if (chiSoSinhTon.huyetApTamThu && chiSoSinhTon.huyetApTamTruong) {
        vitalSignsParts.push(`HA: ${chiSoSinhTon.huyetApTamThu}/${chiSoSinhTon.huyetApTamTruong} mmHg`);
    }
    if (chiSoSinhTon.nhipTho) vitalSignsParts.push(`Nhá»‹p thá»Ÿ: ${chiSoSinhTon.nhipTho} láº§n/phÃºt`);

    // Build paraclinical summary
    const canLamSangParts = [];
    if (canLamSang.congThucMau) canLamSangParts.push(`CÃ´ng thá»©c mÃ¡u: ${canLamSang.congThucMau}`);
    if (canLamSang.sinhHoaMau) canLamSangParts.push(`Sinh hÃ³a mÃ¡u: ${canLamSang.sinhHoaMau}`);
    if (canLamSang.cdhaTdcn) canLamSangParts.push(`CÄHA/TDCN: ${canLamSang.cdhaTdcn}`);

    return {
        THONG_TIN_HOI_CHAN: {
            ngayHoiChan: new Date().toLocaleDateString('vi-VN'),
            capHoiChan: 'Há»™i cháº©n cáº¥p khoa',
            chuTri: 'BÃ¡c sÄ© chá»§ trÃ¬',
            thuKy: 'ThÆ° kÃ½',
            tienLuong: ketLuan.loiDan || 'Theo dÃµi'
        },
        NOI_DUNG_CHUYEN_MON: {
            chiSoSinhTon: vitalSignsParts.join(', ') || null,
            tienSuBanThan: hoiBenh.tienSuBanThan || null,
            tienSuGiaDinh: hoiBenh.tienSuGiaDinh || null,
            diUng: hoiBenh.diUngThuoc || 'KhÃ´ng',
            quaTrinhBenhLy: hoiBenh.quaTrinhBenhLy || null,
            lamSang: lamSangParts.join('. ') || 'KhÃ´ng cÃ³ thÃ´ng tin',
            dienBien: khamLamSang.dienBien || null,
            tomTatCanLamSang: canLamSangParts.join('. ') || 'ChÆ°a cÃ³ káº¿t quáº£',
            chanDoan: chanDoan.cdChinh || chanDoan.cdSoBo || 'ChÆ°a xÃ¡c Ä‘á»‹nh',
            chanDoanKemTheo: chanDoan.cdKemTheo || null,
            chanDoanPhanBiet: chanDoan.cdPhanBiet || null,
            ketLuan: ketLuan.loiDan || chanDoan.moTa || 'Theo dÃµi tiáº¿p',
            huongDieuTri: ketLuan.loiDan || 'Äiá»u trá»‹ theo chá»‰ Ä‘á»‹nh',
            chiDinhXetNghiem: canLamSang.viSinh || null,
            _rawGeminiData: geminiData
        }
    };
};

/**
 * Send audio to transcript API and get result
 */
export const processTranscript = async (audioFilePath) => {
    const transcriptApiUrl = process.env.TRANSCRIPT_API_URL;

    if (!transcriptApiUrl || transcriptApiUrl.includes('your-api.com')) {
        console.warn('âš ï¸ TRANSCRIPT_API_URL not configured. Returning mock data.');
        return getMockTranscriptData();
    }

    try {
        console.log(`ğŸ” DEBUG: audioFilePath = ${audioFilePath}`);
        console.log(`ğŸ” DEBUG: ends with .webm? ${audioFilePath.endsWith('.webm')}`);

        // Convert WebM to WAV for Gemini compatibility
        let wavFilePath = audioFilePath;
        if (audioFilePath.endsWith('.webm')) {
            console.log('ğŸ¬ WebM file detected - starting conversion...');
            try {
                wavFilePath = await convertToWav(audioFilePath);
                console.log(`âœ… Conversion successful! New path: ${wavFilePath}`);
            } catch (conversionError) {
                console.error('âš ï¸ Audio conversion failed, trying with original file:', conversionError.message);
                console.error('ğŸ“‹ Full error:', conversionError);
                // Continue with original file if conversion fails
            }
        } else {
            console.log('â„¹ï¸ Not a WebM file, skipping conversion');
        }

        console.log(`ğŸ“¤ Sending audio to transcript API: ${transcriptApiUrl}`);
        console.log(`ğŸ“ File: ${path.basename(wavFilePath)}`);

        const formData = new FormData();
        formData.append('file', fs.createReadStream(wavFilePath));

        const response = await axios.post(transcriptApiUrl, formData, {
            headers: {
                ...formData.getHeaders(),
            },
            timeout: 120000 // 2 minutes timeout
        });

        console.log('âœ… Transcript received from API');
        console.log('ğŸ“Š Response type:', typeof response.data);

        let geminiData = response.data;

        // If response is string, try to parse
        if (typeof geminiData === 'string') {
            try {
                geminiData = JSON.parse(geminiData);
            } catch (e) {
                console.warn('âš ï¸ Could not parse API response as JSON');
                console.log('Raw response:', geminiData.substring(0, 200));
                return getMockTranscriptData();
            }
        }

        // Check if response has error
        if (geminiData.error || geminiData.status === 'failed') {
            console.warn('âš ï¸ API returned error:', geminiData.error);
            return getMockTranscriptData();
        }

        // Map Gemini's nested structure to our display format
        const transcriptData = mapGeminiResponseToTranscript(geminiData);

        console.log('âœ… Transcript data mapped successfully');
        console.log('ğŸ“‹ Extracted diagnosis:', transcriptData.NOI_DUNG_CHUYEN_MON.chanDoan);

        return transcriptData;

    } catch (error) {
        console.error('âŒ Error calling transcript API:', error.message);
        if (error.response) {
            console.error('API Response Status:', error.response.status);
            console.error('API Response Data:', JSON.stringify(error.response.data).substring(0, 200));
        }
        console.warn('âš ï¸ Falling back to mock data');
        return getMockTranscriptData();
    }
};

/**
 * Mock transcript data for testing
 */
const getMockTranscriptData = () => {
    return {
        THONG_TIN_HOI_CHAN: {
            ngayHoiChan: new Date().toLocaleDateString('vi-VN'),
            capHoiChan: 'Há»™i cháº©n cáº¥p khoa',
            chuTri: 'BÃ¡c sÄ© A',
            thuKy: 'Äiá»u dÆ°á»¡ng C',
            tienLuong: 'TiÃªn lÆ°á»£ng tá»‘t'
        },
        NOI_DUNG_CHUYEN_MON: {
            lamSang: 'Bá»‡nh nhÃ¢n nam, 45 tuá»•i, vÃ o viá»‡n vá»›i triá»‡u chá»©ng Ä‘au ngá»±c, khÃ³ thá»Ÿ.',
            tomTatCanLamSang: 'XÃ©t nghiá»‡m mÃ¡u: WBC tÄƒng nháº¹, CRP 15mg/L. X-quang phá»•i: khÃ´ng tháº¥y tá»•n thÆ°Æ¡ng rÃµ rÃ ng.',
            chanDoan: 'ViÃªm pháº¿ quáº£n cáº¥p',
            chanDoanKemTheo: 'TÄƒng huyáº¿t Ã¡p Ä‘á»™ I',
            ketLuan: 'Äiá»u trá»‹ ná»™i khoa, theo dÃµi sÃ¡t táº¡i khoa Ná»™i.',
            huongDieuTri: 'KhÃ¡ng sinh phá»• rá»™ng, thuá»‘c giÃ£n pháº¿ quáº£n, theo dÃµi dáº¥u hiá»‡u sinh tá»“n.',
            chiDinhXetNghiem: 'XÃ©t nghiá»‡m mÃ¡u toÃ n bá»™, CRP, procalcitonin sau 3 ngÃ y.'
        }
    };
};

/**
 * Clean up old recording files
 */
export const cleanupRecording = (filepath) => {
    try {
        if (fs.existsSync(filepath)) {
            fs.unlinkSync(filepath);
            console.log(`ğŸ—‘ï¸ Cleaned up recording: ${filepath}`);
        }
    } catch (error) {
        console.error('Error cleaning up recording:', error.message);
    }
};
